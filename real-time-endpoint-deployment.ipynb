{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa75994",
   "metadata": {},
   "source": [
    "# Understanding Real-Time Endpoints Architecture\n",
    "Real-time endpoints represent SageMaker's solution for applications that require persistent, high-performance inference infrastructure. Unlike the serverless endpoints you've worked with in previous lessons, real-time endpoints maintain dedicated compute instances that remain active and ready to serve predictions at all times. This architectural approach eliminates the cold start delays that can occur with serverless endpoints when they scale from zero, ensuring that your model can respond to prediction requests with consistent, predictable latency.\n",
    "\n",
    "The key architectural difference lies in the infrastructure persistence model. When you deploy a real-time endpoint, SageMaker provisions dedicated EC2 instances that host your model continuously. These instances run your model in memory, maintaining the loaded state and ready-to-serve configuration that enables immediate response to incoming requests. This persistent architecture makes real-time endpoints particularly well-suited for applications that require guaranteed response times, handle steady streams of prediction requests, or serve as critical components in time-sensitive decision-making processes.\n",
    "\n",
    "Real-time endpoints also provide sophisticated auto-scaling capabilities that allow them to automatically adjust the number of running instances based on incoming traffic patterns. When request volume increases, SageMaker can automatically launch additional instances to maintain performance levels. When traffic decreases, the service can scale down while maintaining a minimum number of instances to ensure availability. This auto-scaling behavior provides the flexibility to handle traffic spikes while maintaining cost efficiency during lower-demand periods.\n",
    "\n",
    "The use cases for real-time endpoints span across industries and applications where immediate responses are critical. Financial services use real-time endpoints for fraud detection systems that must evaluate transactions within milliseconds. E-commerce platforms deploy recommendation engines that provide instant product suggestions as users browse. Healthcare applications rely on real-time endpoints for diagnostic assistance tools that support clinical decision-making. Manufacturing systems use real-time endpoints for quality control processes that must evaluate products as they move through production lines. In each of these scenarios, the consistent low latency and high availability provided by real-time endpoints are essential for the application's success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d5096",
   "metadata": {},
   "source": [
    "# Finding and Preparing the Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d09b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# List most recent completed training job\n",
    "training_jobs = sagemaker_session.sagemaker_client.list_training_jobs(\n",
    "    SortBy='CreationTime',                 # Sort jobs by creation time\n",
    "    SortOrder='Descending',                # Newest jobs first\n",
    "    StatusEquals='Completed',              # Only include completed jobs\n",
    "    NameContains='sagemaker-scikit-learn'  # Filter to sklearn estimator jobs\n",
    ")\n",
    "\n",
    "# Extract the name of the latest training job of the list\n",
    "TRAINING_JOB_NAME = training_jobs['TrainingJobSummaries'][0]['TrainingJobName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c383b",
   "metadata": {},
   "source": [
    "# Configuring Real-Time Endpoint Resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique name to assign to the deployed real-time endpoint\n",
    "ENDPOINT_NAME = \"california-housing-realtime\"\n",
    "# Type of instance to use for the endpoint\n",
    "INSTANCE_TYPE = \"ml.m5.large\"\n",
    "# Number of instances to launch for the endpoint\n",
    "INSTANCE_COUNT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a6875",
   "metadata": {},
   "source": [
    "# Executing the Deployment and Monitoring Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach to existing training job\n",
    "estimator = SKLearn.attach(TRAINING_JOB_NAME)\n",
    "\n",
    "# Deploy as real-time endpoint\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=INSTANCE_COUNT,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    wait=False\n",
    ")\n",
    "\n",
    "# Retrieve detailed information about the specified SageMaker endpoint\n",
    "endpoint_description = sagemaker_session.sagemaker_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "\n",
    "# Extract the current status of the endpoint from the response\n",
    "status = endpoint_description['EndpointStatus']\n",
    "\n",
    "# Display the endpoint's status\n",
    "print(f\"Endpoint status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cadc5",
   "metadata": {},
   "source": [
    "# Considerations for Real-Time Endpoint Usage\n",
    "\n",
    "Before deploying real-time endpoints in production, you must understand the key trade-offs that will impact both performance and costs. These considerations help determine when real-time endpoints are the optimal choice for your specific use case.\n",
    "\n",
    "- Cost implications: Real-time endpoints incur continuous costs for all provisioned instances regardless of usage, unlike serverless endpoints that only charge for actual requests. This makes them most economical for steady, predictable traffic patterns.\n",
    "\n",
    "- Instance selection and sizing: Balance your model's resource requirements against costs. Instances like ml.m5.large provide a good balance of performance and cost for many workloads, while smaller instances like ml.t3.medium may be more economical for lightweight models. Larger instances like ml.m5.xlarge or ml.c5.2xlarge provide more power at proportionally higher costs. GPU-enabled instances (ml.p3 or ml.g4dn families) may be necessary for deep learning models but significantly increase costs.\n",
    "\n",
    "- Scaling and availability: Production deployments typically need multiple instances for redundancy and traffic handling. Auto-scaling takes time as new instances must launch and initialize, requiring proactive rather than reactive scaling policies.\n",
    "\n",
    "- Monitoring and maintenance: Real-time endpoints require continuous monitoring of instance health, performance metrics, and scaling behavior. Model updates need careful coordination across running instances to minimize downtime.\n",
    "\n",
    "These considerations help you choose between serverless and real-time endpoints based on your traffic patterns, latency requirements, and budget constraints rather than technical preferences alone."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
