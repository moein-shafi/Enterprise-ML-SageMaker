{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353d5096",
   "metadata": {},
   "source": [
    "# Finding and Preparing the Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d09b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Create a SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# List most recent completed training job\n",
    "training_jobs = sagemaker_session.sagemaker_client.list_training_jobs(\n",
    "    SortBy='CreationTime',                 # Sort jobs by creation time\n",
    "    SortOrder='Descending',                # Newest jobs first\n",
    "    StatusEquals='Completed',              # Only include completed jobs\n",
    "    NameContains='sagemaker-scikit-learn'  # Filter to sklearn estimator jobs\n",
    ")\n",
    "\n",
    "# Extract the name of the latest training job of the list\n",
    "TRAINING_JOB_NAME = training_jobs['TrainingJobSummaries'][0]['TrainingJobName']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c383b",
   "metadata": {},
   "source": [
    "# Configuring Real-Time Endpoint Resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique name to assign to the deployed real-time endpoint\n",
    "ENDPOINT_NAME = \"california-housing-realtime\"\n",
    "# Type of instance to use for the endpoint\n",
    "INSTANCE_TYPE = \"ml.m5.large\"\n",
    "# Number of instances to launch for the endpoint\n",
    "INSTANCE_COUNT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a6875",
   "metadata": {},
   "source": [
    "# Executing the Deployment and Monitoring Status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbb417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach to existing training job\n",
    "estimator = SKLearn.attach(TRAINING_JOB_NAME)\n",
    "\n",
    "# Deploy as real-time endpoint\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=INSTANCE_COUNT,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    wait=False\n",
    ")\n",
    "\n",
    "# Retrieve detailed information about the specified SageMaker endpoint\n",
    "endpoint_description = sagemaker_session.sagemaker_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "\n",
    "# Extract the current status of the endpoint from the response\n",
    "status = endpoint_description['EndpointStatus']\n",
    "\n",
    "# Display the endpoint's status\n",
    "print(f\"Endpoint status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cadc5",
   "metadata": {},
   "source": [
    "# Considerations for Real-Time Endpoint Usage\n",
    "\n",
    "Before deploying real-time endpoints in production, you must understand the key trade-offs that will impact both performance and costs. These considerations help determine when real-time endpoints are the optimal choice for your specific use case.\n",
    "\n",
    "- Cost implications: Real-time endpoints incur continuous costs for all provisioned instances regardless of usage, unlike serverless endpoints that only charge for actual requests. This makes them most economical for steady, predictable traffic patterns.\n",
    "\n",
    "- Instance selection and sizing: Balance your model's resource requirements against costs. Instances like ml.m5.large provide a good balance of performance and cost for many workloads, while smaller instances like ml.t3.medium may be more economical for lightweight models. Larger instances like ml.m5.xlarge or ml.c5.2xlarge provide more power at proportionally higher costs. GPU-enabled instances (ml.p3 or ml.g4dn families) may be necessary for deep learning models but significantly increase costs.\n",
    "\n",
    "- Scaling and availability: Production deployments typically need multiple instances for redundancy and traffic handling. Auto-scaling takes time as new instances must launch and initialize, requiring proactive rather than reactive scaling policies.\n",
    "\n",
    "- Monitoring and maintenance: Real-time endpoints require continuous monitoring of instance health, performance metrics, and scaling behavior. Model updates need careful coordination across running instances to minimize downtime.\n",
    "\n",
    "These considerations help you choose between serverless and real-time endpoints based on your traffic patterns, latency requirements, and budget constraints rather than technical preferences alone."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
